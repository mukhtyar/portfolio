---
layout: ../../layouts/BlogPostLayout.astro
title: Building a question-answer system with Vertex AI
client: Self
publishDate: 2023-12-12 00:00:00
description: Building a simple question-answer system is a great place to practice your data science skills.
tags:
  - data-science
  - learning
  - vertex ai
---

If you have been struggling with coming up with a project to test out data science skills you learned in online courses, building a simple question-answer system is a great place to start.

## What's a question-answer system?
A question-answer system is an AI application that:
- takes a user's question
- converts it into a numerical format (aka a [text embedding](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-embeddings))
- searches a store of information that you specify ( e.g. database, document, web) which is in the same numerical format
- finds the most relevant content
- sends this content to a large language model (LLM) as `context`
- generates an answer via the LLM using a `prompt` that you design and the `context` you provide

In deep learning speak, this is an example of Retrieval-Augmented Generation (RAG). This [article](https://inside-machinelearning.com/en/rag/) has a great explantion of RAG. Some applications of a question-asnwer system are automating the creation of a Frequently Asked Questions document from a knowledge base or creating a Virtual Assistant.

## How do I build one?
A short course on DeepLearning.AI called Understanding and Applying Text Embeddings is a great guide to getting started on this project. The course (which is free for now) walks you through building a question-answer system using Google's [Vertex AI](https://cloud.google.com/vertex-ai).

Vertex AI is a machine learning platform by Google where you can build, deploy, and scale AI models with pre-trained and custom models. Your first challenge will be setting up a Google Cloud account and creating a project. If you havent already done this, here is a good [walkthrough]().

I chose to use the Vertex AI SDK for Python in Kaggle notebooks, but it might be easier to use the library on Google platforms like the Vertex AI Workbench (a Jupyter notebook-based development environment provided by Google Cloud) or Google Colab.

### Get some data!
Your second challenge is identify some question-answer data you want to work with. There are lot of great datasets on Kaggle, or you can create your own like I did. I love gardening, so I decided to work with data generated by the Stack Exchange Gardening and Landscaping community. The [Stack Exchange Data Explorer](https://data.stackexchange.com/) is a great resource for downloading question-answer data. I created a dataset on Kaggle with a csv file of questions and accepted answers. The [Gardening Q&A with text embeddings](https://www.kaggle.com/datasets/shrutimukhtyar/stack-exchange-gardening-and-landscaping) is publicly available from Kaggle. The dataset also includes the text embeddings generated by Vertex AI models for questions and tags.

### Write some code :-)
The following Kaggle notebooks walk you through building a simple system that will answer any queries you have on gardening. 
- [Vertex AI: Setup environment on Kaggle](https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-setup-environment-on-kaggle)
- [Vertex AI: Generate Text Embeddings](https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-generate-text-embeddings)
- [Vertex AI: Visualizing text embeddings](https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-visualizing-text-embeddings)ions.
- [Vertex AI: Q&A system using semantic search](https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-q-a-system-using-semantic-search)

## Lessons learned
- It was really confusing figruing out the Google AI ecosystem. The course focuses on using 2 models called `textembedding-gecko` and `text-bison` available through Vertex AI. From what I now understand here's a quick run through of the Google AI ecosystem: 
  - PaLM 2 and Gemini are two different foundation models developed by Google. PaLM 2 is a LLM that specializes in natural language understanding and generation (and powers Bard). Gemini is a multimodal LLM that can handle different types of data, such as text, images, audio, and code. [This article](https://bito.ai/blog/gemini-vs-palm2/) describes both in more detail.
  - Both `textembedding-gecko` and `text-bison`belong to the PaLM 2 family.
  - Vertex AI provides access to [both foundation models through different APIs](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)
- I generated the text embeddings using the `textembedding-gecko@003` model. The body of questions on Stack Exchange often contain html elements like links and images. I did not remove these elements before sending them to Vertex AI to generate embeddings. But after looking at the answers the system generated, it's possible that removing these elements and other stop words, might result in better performance.
- I went with the prompt used in the course. But the prompt in combination with the context that I sent to the `text-bison@002` text generation model did not always generate the best answer.
  - One interpretation of this could be that the Stack Exchange dataset does not have the best answers, compared to general training data that the PaLM 2 model was trained on.
  - Another way to think about this is that in a topic like gardening there are many good answers. In the [Vertex AI: Q&A system using semantic search](https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-q-a-system-using-semantic-search) notebook, I select 1 question-answer that's closest semantically to the user's query as `context`. Instead, if I selected more than 1 relevant question-answers as `context`, the system would generate a better response. The maximum length the context can be for a PaLM 2 mode is about [8000 tokens](https://ai.google.dev/models/palm) (100 tokens are about 60-80 English words.).
- Using a different prompt that instructed the LLM to use both context and it's training data to generate answers would have probably produced more relevant answers for a topic like gardening.

It was fun putting this together! While I would not use the system I built to answer any of my gardening questions as yet, I learned a lot about Google's AI ecosystem and about dealing with real-world data and its challenges.
