<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
<meta name="description" property="og:description" content="Building a simple question-answer system is a great way to practice your data science skills.">
<meta name="viewport" content="width=device-width">
<title>Building a question-answer system with Vertex AI</title>
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css?family=Work+Sans:400,500" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Spirax&text=ShrutiMukhtyar" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PTG1RDVD45"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());

  gtag("config", "G-PTG1RDVD45");
</script>

  <link rel="stylesheet" href="/assets/Button.7eb550c2.css"></link>
<link rel="stylesheet" href="/assets/BlogPostLayout.efaf7ca4.css"></link>
<link rel="stylesheet" href="/assets/Footer.24b62fab.css"></link><style astro-style="true">astro-root, astro-fragment { display: contents; }</style><script type="module" data-astro-component-hydration astro-script="/blog/vertexai-exploration/script-0">import setup from '../../load.28fdc308.js';
setup("Z1TC7mX", {name:"Nav",value: true}, async () => {
  const [{ default: Component }, { default: hydrate }] = await Promise.all([import("../../Nav.75862199.js"), import("../../client.f1fece1f.js")]);
  return (el, children) => hydrate(el)(Component, {"routes":[{"path":"\u002Fprojects","label":"Projects"},{"path":"\u002Fblog","label":"Blog"},{"path":"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fshruti-mukhtyar\u002F","label":"LinkedIn","icon":{"render":(props = {}, { $slots = {}, context = new Map() } = {}) => {
            on_destroy = [];
            const result = { title: '', head: '', css: new Set() };
            const html = $render(result, props, {}, $slots, context);
            run_all(on_destroy);
            return {
                html,
                css: {
                    code: Array.from(result.css).map(css => css.code).join('\n'),
                    map: null // TODO
                },
                head: result.title + result.head
            };
        },"$render":function $render(result, props, bindings, slots, context) {
        const parent_component = current_component;
        const $ = {
            on_destroy,
            context: new Map(context || (parent_component ? parent_component.$.context : [])),
            // these will be immediately discarded
            on_mount: [],
            before_update: [],
            after_update: [],
            callbacks: blank_object()
        };
        set_current_component({ $ });
        const html = fn(result, props, bindings, slots);
        set_current_component(parent_component);
        return html;
    }}},{"path":"https:\u002F\u002Fgithub.com\u002Fmukhtyar","label":"Github","icon":{"render":(props = {}, { $slots = {}, context = new Map() } = {}) => {
            on_destroy = [];
            const result = { title: '', head: '', css: new Set() };
            const html = $render(result, props, {}, $slots, context);
            run_all(on_destroy);
            return {
                html,
                css: {
                    code: Array.from(result.css).map(css => css.code).join('\n'),
                    map: null // TODO
                },
                head: result.title + result.head
            };
        },"$render":function $render(result, props, bindings, slots, context) {
        const parent_component = current_component;
        const $ = {
            on_destroy,
            context: new Map(context || (parent_component ? parent_component.$.context : [])),
            // these will be immediately discarded
            on_mount: [],
            before_update: [],
            after_update: [],
            callbacks: blank_object()
        };
        set_current_component({ $ });
        const html = fn(result, props, bindings, slots);
        set_current_component(parent_component);
        return html;
    }}},{"path":"https:\u002F\u002Fobservablehq.com\u002F@mukhtyar?type=collections","label":"ObservableHQ","icon":{"render":(props = {}, { $slots = {}, context = new Map() } = {}) => {
            on_destroy = [];
            const result = { title: '', head: '', css: new Set() };
            const html = $render(result, props, {}, $slots, context);
            run_all(on_destroy);
            return {
                html,
                css: {
                    code: Array.from(result.css).map(css => css.code).join('\n'),
                    map: null // TODO
                },
                head: result.title + result.head
            };
        },"$render":function $render(result, props, bindings, slots, context) {
        const parent_component = current_component;
        const $ = {
            on_destroy,
            context: new Map(context || (parent_component ? parent_component.$.context : [])),
            // these will be immediately discarded
            on_mount: [],
            before_update: [],
            after_update: [],
            callbacks: blank_object()
        };
        set_current_component({ $ });
        const html = fn(result, props, bindings, slots);
        set_current_component(parent_component);
        return html;
    }}},{"path":"https:\u002F\u002Fwww.kaggle.com\u002Fshrutimukhtyar","label":"Kaggle","icon":{"render":(props = {}, { $slots = {}, context = new Map() } = {}) => {
            on_destroy = [];
            const result = { title: '', head: '', css: new Set() };
            const html = $render(result, props, {}, $slots, context);
            run_all(on_destroy);
            return {
                html,
                css: {
                    code: Array.from(result.css).map(css => css.code).join('\n'),
                    map: null // TODO
                },
                head: result.title + result.head
            };
        },"$render":function $render(result, props, bindings, slots, context) {
        const parent_component = current_component;
        const $ = {
            on_destroy,
            context: new Map(context || (parent_component ? parent_component.$.context : [])),
            // these will be immediately discarded
            on_mount: [],
            before_update: [],
            after_update: [],
            callbacks: blank_object()
        };
        set_current_component({ $ });
        const html = fn(result, props, bindings, slots);
        set_current_component(parent_component);
        return html;
    }}}],"currentRoute":undefined}, children);

});
</script>
</head>
  <body>
    <astro-root uid="Z1TC7mX"><nav class="svelte-1235unm"><div><a class="brand svelte-1235unm" href="/">Shruti Mukhtyar</a></div>
  <ul role="menu" class="svelte-1235unm"><li class="svelte-1235unm"><a aria-current="false" href="/projects" class="svelte-1235unm">Projects</a>
      </li><li class="svelte-1235unm"><a aria-current="false" href="/blog" class="svelte-1235unm">Blog</a>
      </li><li class="svelte-1235unm"><a aria-current="false" href="https://www.linkedin.com/in/shruti-mukhtyar/" class="svelte-1235unm"><svg width="30" height="30" fill="currentColor" aria-hidden aria-labelledby="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M26.2,4H5.8C4.8,4,4,4.8,4,5.7v20.5c0,0.9,0.8,1.7,1.8,1.7h20.4c1,0,1.8-0.8,1.8-1.7V5.7C28,4.8,27.2,4,26.2,4z M11.1,24.4 H7.6V13h3.5V24.4z M9.4,11.4c-1.1,0-2.1-0.9-2.1-2.1c0-1.2,0.9-2.1,2.1-2.1c1.1,0,2.1,0.9,2.1,2.1S10.5,11.4,9.4,11.4z M24.5,24.3 H21v-5.6c0-1.3,0-3.1-1.9-3.1c-1.9,0-2.1,1.5-2.1,2.9v5.7h-3.5V13h3.3v1.5h0.1c0.5-0.9,1.7-1.9,3.4-1.9c3.6,0,4.3,2.4,4.3,5.5V24.3z"></path></svg>
            <span class="sr-only">LinkedIn</span></a>
      </li><li class="svelte-1235unm"><a aria-current="false" href="https://github.com/mukhtyar" class="svelte-1235unm"><svg width="30" height="30" fill="currentColor" aria-hidden aria-labelledby="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M16,2a14,14,0,0,0-4.43,27.28c.7.13,1-.3,1-.67s0-1.21,0-2.38c-3.89.84-4.71-1.88-4.71-1.88A3.71,3.71,0,0,0,6.24,22.3c-1.27-.86.1-.85.1-.85A2.94,2.94,0,0,1,8.48,22.9a3,3,0,0,0,4.08,1.16,2.93,2.93,0,0,1,.88-1.87c-3.1-.36-6.37-1.56-6.37-6.92a5.4,5.4,0,0,1,1.44-3.76,5,5,0,0,1,.14-3.7s1.17-.38,3.85,1.43a13.3,13.3,0,0,1,7,0c2.67-1.81,3.84-1.43,3.84-1.43a5,5,0,0,1,.14,3.7,5.4,5.4,0,0,1,1.44,3.76c0,5.38-3.27,6.56-6.39,6.91a3.33,3.33,0,0,1,.95,2.59c0,1.87,0,3.38,0,3.84s.25.81,1,.67A14,14,0,0,0,16,2Z"></path></svg>
            <span class="sr-only">Github</span></a>
      </li><li class="svelte-1235unm"><a aria-current="false" href="https://observablehq.com/@mukhtyar?type=collections" class="svelte-1235unm"><svg width="30" height="30" fill="currentColor" aria-hidden aria-labelledby="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 26 28"><path d="M12.5 22.6667C11.3458 22.6667 10.3458 22.4153 9.5 21.9127C8.65721 21.412 7.98339 20.7027 7.55521 19.8654C7.09997 18.9942 6.76672 18.0729 6.56354 17.1239C6.34796 16.0947 6.24294 15.0483 6.25 14C6.25 13.1699 6.30417 12.3764 6.41354 11.6176C6.52188 10.8598 6.72292 10.0894 7.01563 9.30748C7.30833 8.52555 7.68542 7.84763 8.14479 7.27274C8.62304 6.68378 9.24141 6.20438 9.95208 5.87163C10.6979 5.51244 11.5458 5.33333 12.5 5.33333C13.6542 5.33333 14.6542 5.58467 15.5 6.08733C16.3428 6.588 17.0166 7.29733 17.4448 8.13459C17.8969 8.99644 18.2271 9.9103 18.4365 10.8761C18.6448 11.841 18.75 12.883 18.75 14C18.75 14.8301 18.6958 15.6236 18.5865 16.3824C18.4699 17.1702 18.2639 17.9446 17.9719 18.6925C17.6698 19.4744 17.2948 20.1524 16.8427 20.7273C16.3906 21.3021 15.7927 21.7692 15.0479 22.1284C14.3031 22.4876 13.4542 22.6667 12.5 22.6667ZM14.7063 16.2945C15.304 15.6944 15.6365 14.864 15.625 14C15.625 13.1073 15.326 12.3425 14.7292 11.7055C14.1313 11.0685 13.3885 10.75 12.5 10.75C11.6115 10.75 10.8688 11.0685 10.2708 11.7055C9.68532 12.3123 9.36198 13.1405 9.375 14C9.375 14.8927 9.67396 15.6575 10.2708 16.2945C10.8688 16.9315 11.6115 17.25 12.5 17.25C13.3885 17.25 14.124 16.9315 14.7063 16.2945ZM12.5 27C19.4031 27 25 21.1792 25 14C25 6.82075 19.4031 1 12.5 1C5.59687 1 0 6.82075 0 14C0 21.1792 5.59687 27 12.5 27Z"></path></svg>
            <span class="sr-only">ObservableHQ</span></a>
      </li><li class="svelte-1235unm"><a aria-current="false" href="https://www.kaggle.com/shrutimukhtyar" class="svelte-1235unm"><svg width="30" height="30" fill="currentColor" aria-hidden aria-labelledby="false" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M385.708,476.478L254.742,313.713l125.578-121.534c2.334-2.426,1.526-9.433-4.761-9.433h-62.16    c-3.145,0-6.288,1.618-9.433,4.761L185.128,307.604V32.738c0-4.491-2.247-6.737-6.738-6.737h-46.618    c-4.492,0-6.737,2.246-6.737,6.737v446.433c0,4.491,2.246,6.738,6.737,6.738h46.618c4.491,0,6.738-2.247,6.738-6.738v-97.91    l27.666-26.317l99.257,126.294c2.695,3.145,5.839,4.762,9.432,4.762h60.095c3.143,0,4.939-0.899,5.389-2.696L385.708,476.478z"></path></svg>
            <span class="sr-only">Kaggle</span></a>
      </li></ul></nav></astro-root>
    <main id="main">
      <section class="astro-Q2WAGKRZ">
    <div class="container astro-Q2WAGKRZ">
      <div class="blog-top-content astro-Q2WAGKRZ">
        <h1 class="astro-Q2WAGKRZ">Building a question-answer system with Vertex AI</h1>
        <p class="astro-Q2WAGKRZ">
          Wednesday, February 7, 2024
        </p>
      </div>

      <div class="blog-divider astro-Q2WAGKRZ"></div>

      <div class="blog-content astro-Q2WAGKRZ">
        <p>If you are looking for a project idea to practice the data science skills you acquired through online courses, building a simple question-answer system is a great place to start.</p><h2 id="whats-a-question-answer-system">What’s a question-answer system?</h2><p>A question-answer system is an AI application that:</p><ul>
<li>takes a user’s question</li>
<li>converts it into a numerical format (aka <a href="https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-embeddings">text embedding</a>)</li>
<li>searches a store of information that you specify ( e.g. database, document, web) which is in the same numerical format (aka semantic search)</li>
<li>finds the most relevant content</li>
<li>sends this content to a large language model (LLM) as <code>context</code></li>
<li>generates an answer via the LLM using a <code>prompt</code> that you design and the <code>context</code> you provide</li>
</ul><p>In deep learning speak, this is an example of Retrieval-Augmented Generation (RAG). This <a href="https://inside-machinelearning.com/en/rag/">article</a> has a great explantion of RAG. One application of a question-asnwer system is automating the creation of a Frequently Asked Questions document from a knowledge base.</p><h2 id="how-do-i-build-one">How do I build one?</h2><p>A short course on DeepLearning.AI called Understanding and Applying Text Embeddings is a great guide to getting started on this project. The course (which is free for now) walks you through building a question-answer system using Google’s <a href="https://cloud.google.com/vertex-ai">Vertex AI</a>.</p><p>Vertex AI is a machine learning platform by Google where you can build, deploy, and scale AI models with pre-trained and custom models. Your first challenge will be setting up a Google Cloud account and creating a project. If you you need help with this, here is a good <a href="">walkthrough</a>. My Google Cloud computing costs for generating text embeddings for about 7000 records a few times was less than a $1.</p><p>I chose to use the Vertex AI SDK for Python in Kaggle notebooks, but it might be easier to use the library on Google platforms like the Vertex AI Workbench (a Jupyter notebook-based development environment provided by Google Cloud) or Google Colab.</p><h3 id="get-some-data">Get some data!</h3><p>Your second challenge is identify some question-answer data you want to work with. There are lot of great datasets on Kaggle, or you can create your own like I did. I love gardening, so I decided to work with data generated by the Stack Exchange Gardening and Landscaping community. The <a href="https://data.stackexchange.com/">Stack Exchange Data Explorer</a> is a great resource for downloading question-answer data. I created a dataset on Kaggle with a csv file of questions and accepted answers. The <a href="https://www.kaggle.com/datasets/shrutimukhtyar/stack-exchange-gardening-and-landscaping">Gardening Q&#x26;A with text embeddings</a> is publicly available from Kaggle. The dataset also includes the text embeddings generated by Vertex AI models for questions and tags.</p><h3 id="write-some-code--">Write some code :-)</h3><p>The following Kaggle notebooks walk you through building a simple system that will answer any queries you have on gardening.</p><ul>
<li><a href="https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-setup-environment-on-kaggle">Vertex AI: Setup environment on Kaggle</a></li>
<li><a href="https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-generate-text-embeddings">Vertex AI: Generate Text Embeddings</a></li>
<li><a href="https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-visualizing-text-embeddings">Vertex AI: Visualizing text embeddings</a></li>
<li><a href="https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-q-a-system-using-semantic-search">Vertex AI: Q&#x26;A system using semantic search</a></li>
</ul><h2 id="lessons-learned">Lessons learned</h2><ul>
<li>Initially, navigating the Google AI ecosystem was confusing. The course uses 2 models called <code>textembedding-gecko</code> and <code>text-bison</code> accessible via Vertex AI. Based on my current understanding, here is a brief overview of the Google AI ecosystem:
<ul>
<li>PaLM 2 and Gemini are two different foundation models developed by Google (there some <a href="https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview">others</a> too). PaLM 2 is a LLM that specializes in natural language understanding and generation (it is the power behind Bard). Gemini is a multimodal LLM that can handle different types of data, such as text, images, audio, and code. <a href="https://bito.ai/blog/gemini-vs-palm2/">This article</a> describes both in more detail.</li>
<li>Both <code>textembedding-gecko</code> and <code>text-bison</code> belong to the PaLM 2 family.</li>
<li>Vertex AI provides access to all PaLM 2 and Geimini models <a href="https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models">through different APIs</a></li>
</ul>
</li>
<li>The body of some questions on Stack Exchange contain html elements like links and images. I did not remove these elements before sending them to Vertex AI to generate text embeddings using the <code>textembedding-gecko@003</code> model. I remember reading somewhere that the <code>textembedding-gecko</code> model will just ignore these html elements, but after looking at the answers the system generated, it’s possible that removing these elements might generate better text embeddings.</li>
<li>I followed the prompt provided in the course, yet the combination of this prompt and the context I supplied to the <code>text-bison@002</code> text generation model did not consistently yield the best answers.
<ul>
<li>One interpretation of this could be that the Stack Exchange dataset does not have the best answers, compared to the general training data that the PaLM 2 foundation model was trained on.</li>
<li>Another way to think about this is that in a topic like gardening there are many good answers. In the <a href="https://www.kaggle.com/code/shrutimukhtyar/vertex-ai-q-a-system-using-semantic-search">Vertex AI: Q&#x26;A system using semantic search</a> notebook, I select only 1 question-answer that’s closest semantically to the user’s query and provide it as as <code>context</code>. Instead, if I selected more than 1 relevant question-answers as <code>context</code>, the system would generate a better response. The maximum length of text you can send a PaLM 2 model is about <a href="https://ai.google.dev/models/palm">8000 tokens</a> (100 tokens are about 60-80 English words).</li>
</ul>
</li>
<li>Using an alternative prompt that directs the LLM to leverage both the provided context and its training data for answer generation might result in more relevant answers for a gardening Q&#x26;A.</li>
</ul><p>It was fun putting this together! Although my gardening question-answer system lot of room for improvement, I gained considerable insight into Google’s AI ecosystem, as well as valuable experience in handling real-world data and navigating its complexities.</p>
      </div>
    </div>
  </section>
    </main>
    <footer class="svelte-3a94zn"><ul role="menu" class="svelte-3a94zn"><li class="svelte-3a94zn"><a aria-current="false" href="/" class="svelte-3a94zn">Home
      </a></li>
    <li class="svelte-3a94zn"><a aria-current="false" href="/projects" class="svelte-3a94zn">Projects</a>
        </li><li class="svelte-3a94zn"><a aria-current="false" href="/blog" class="svelte-3a94zn">Blog</a>
        </li></ul>

  <div>🚀 Built with <a href="https://astro.build/" target="_blank" class="svelte-3a94zn">Astro</a>,
    <a href="https://svelte.dev/" target="_blank" class="svelte-3a94zn">Svelte</a>
    &amp; <a href="https://open-props.style" target="_blank" class="svelte-3a94zn">Open Props</a></div></footer>
  </body></html>


